{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目录\n",
    "## 1. 导入模块\n",
    "## 2. tf.data.Dataset.from_tensor_slices\n",
    "### 2.1 一维数组\n",
    "### 2.2 二位数组\n",
    "### 2.3 元组\n",
    "### 2.4 字典\n",
    "### 2.5 组合\n",
    "  \n",
    "## 3. shuffle的使用\n",
    "## 4. repeat batch 的使用\n",
    "## 5. take 从dataset取几个元素\n",
    "## 6. interleave\n",
    "## 7.  map的用法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.18.1\n",
      "pandas 0.25.3\n",
      "matplotlib 3.1.2\n",
      "sklearn 0.22.1\n",
      "tensorflow_core.python.keras.api._v2.keras 2.2.4-tf\n",
      "tensorflow 2.1.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "for module in [np, pd, mpl, sklearn, keras, tf]:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. tf.data.Dataset.from_tensor_slices\n",
    ">该api的作用是，把内存的数据分装成`dataset`，并且`dataset`是一个迭代器；往里面传什么样的格式(元组，字典)数据，迭代的时候就返回什么样的格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 一维数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (), types: tf.int64>\n"
     ]
    }
   ],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensor_slices(np.arange(10))\n",
    "print(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset1:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 二维数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-1.48846764 -0.88762542 -1.20111511], shape=(3,), dtype=float64)\n",
      "tf.Tensor([-0.10914715 -1.69061133 -1.19204482], shape=(3,), dtype=float64)\n",
      "tf.Tensor([ 0.02946257 -0.56475841 -0.78798879], shape=(3,), dtype=float64)\n",
      "tf.Tensor([ 0.80156687 -0.38138432 -0.21904758], shape=(3,), dtype=float64)\n",
      "tf.Tensor([ 0.70102761 -0.00352738  0.43777427], shape=(3,), dtype=float64)\n",
      "tf.Tensor([-0.28952003 -1.8086101   2.18609337], shape=(3,), dtype=float64)\n",
      "tf.Tensor([-0.03285051  0.4882148   1.08820751], shape=(3,), dtype=float64)\n",
      "tf.Tensor([ 0.30932759 -0.07884757 -0.3462364 ], shape=(3,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensor_slices(np.random.normal(size=(8, 3)))\n",
    "for item in dataset1:\n",
    "    print(item)                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 元组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2.]\n",
      "*****\n",
      "b'cat'\n",
      "==========\n",
      "[3. 4.]\n",
      "*****\n",
      "b'dog'\n",
      "==========\n",
      "[5. 6.]\n",
      "*****\n",
      "b'fox'\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "y = np.array([\"cat\", \"dog\", \"fox\"])\n",
    "\n",
    "dataset1 = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "for item_x, item_y in dataset1:\n",
    "    print(item_x.numpy())\n",
    "    print(\"*\"*5)\n",
    "    print(item_y.numpy())\n",
    "    print(\"=\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 2.], shape=(2,), dtype=float64)\n",
      "*****\n",
      "tf.Tensor(b'cat', shape=(), dtype=string)\n",
      "==========\n",
      "tf.Tensor([3. 4.], shape=(2,), dtype=float64)\n",
      "*****\n",
      "tf.Tensor(b'dog', shape=(), dtype=string)\n",
      "==========\n",
      "tf.Tensor([5. 6.], shape=(2,), dtype=float64)\n",
      "*****\n",
      "tf.Tensor(b'fox', shape=(), dtype=string)\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensor_slices({\"features\": x, \"labels\": y})\n",
    "for item in dataset1:\n",
    "    print(item[\"features\"])\n",
    "    print(\"*\"*5)\n",
    "    print(item[\"labels\"])\n",
    "    print(\"=\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 混合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'features': <tf.Tensor: shape=(2,), dtype=float64, numpy=array([1., 2.])>, 'labels': <tf.Tensor: shape=(), dtype=string, numpy=b'cat'>} --------> tf.Tensor(1, shape=(), dtype=int32)\n",
      "{'features': <tf.Tensor: shape=(2,), dtype=float64, numpy=array([3., 4.])>, 'labels': <tf.Tensor: shape=(), dtype=string, numpy=b'dog'>} --------> tf.Tensor(2, shape=(), dtype=int32)\n",
      "{'features': <tf.Tensor: shape=(2,), dtype=float64, numpy=array([5., 6.])>, 'labels': <tf.Tensor: shape=(), dtype=string, numpy=b'fox'>} --------> tf.Tensor(3, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensor_slices(({\"features\": x, \"labels\": y}, [1, 2, 3]))\n",
    "for item1, item2 in dataset1:\n",
    "    print(item1, \"-------->\", item2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. shuffle的使用\n",
    ">作用是把`dataset`的数据打乱顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'features': <tf.Tensor: shape=(2,), dtype=float64, numpy=array([1., 2.])>, 'labels': <tf.Tensor: shape=(), dtype=string, numpy=b'cat'>}, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n",
      "({'features': <tf.Tensor: shape=(2,), dtype=float64, numpy=array([3., 4.])>, 'labels': <tf.Tensor: shape=(), dtype=string, numpy=b'dog'>}, <tf.Tensor: shape=(), dtype=int32, numpy=2>)\n",
      "({'features': <tf.Tensor: shape=(2,), dtype=float64, numpy=array([5., 6.])>, 'labels': <tf.Tensor: shape=(), dtype=string, numpy=b'fox'>}, <tf.Tensor: shape=(), dtype=int32, numpy=3>)\n"
     ]
    }
   ],
   "source": [
    "dataset1 = dataset1.shuffle(10000)\n",
    "for item in dataset1:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. repeat  batch 的使用\n",
    "> repeat 重复几分数据 <br/>\n",
    "batch 每一个迭代出的元素包含几份数据 <br/>\n",
    "如果repeat()没有传入数据，则重复无限次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset2 = tf.data.Dataset.from_tensor_slices(np.arange(5))\n",
    "dataset2 = dataset2.repeat(3) # 重复3份数据\n",
    "for item in dataset2:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3], shape=(4,), dtype=int64)\n",
      "tf.Tensor([4 0 1 2], shape=(4,), dtype=int64)\n",
      "tf.Tensor([3 4 0 1], shape=(4,), dtype=int64)\n",
      "tf.Tensor([2 3 4], shape=(3,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset2 = dataset2.batch(4) # 一个元素快 4个数据样本\n",
    "for item in dataset2:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 4 3 1], shape=(4,), dtype=int64)\n",
      "tf.Tensor([2 1 0 3], shape=(4,), dtype=int64)\n",
      "tf.Tensor([4 2 1 4], shape=(4,), dtype=int64)\n",
      "tf.Tensor([0 2 3], shape=(3,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 联合使用\n",
    "# 1. 从内存分装一个dataset    from_tensor_slices\n",
    "# 2. 打乱顺序   shuffle\n",
    "# 3. 重复epoch，即数据复制几份  repeat\n",
    "# 4. 定义元素块   batch\n",
    "\n",
    "dataset3 = tf.data.Dataset.from_tensor_slices(np.arange(5))\n",
    "dataset3 = dataset3.shuffle(10000)\n",
    "dataset3 = dataset3.repeat(3).batch(4)\n",
    "\n",
    "for item in dataset3:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. take 从dataset取几个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset4 = tf.data.Dataset.from_tensor_slices(np.arange(10))\n",
    "\n",
    "for item in dataset4.take(2):  # 取两个元素\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. interleave\n",
    ">作用是处理`dataset`的元素，并返回的数据，聚合成一个新的`dataset` <br/>\n",
    "用例：第一的dataset分装数据文件名称，使用interleave 处理dataset里的每一个文件名，读取数据，所有文件数据返回一个新的dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64)\n",
      "tf.Tensor([5 6 7 8 0], shape=(5,), dtype=int64)\n",
      "tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int64)\n",
      "tf.Tensor([6 7 8], shape=(3,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset5 = tf.data.Dataset.from_tensor_slices(np.arange(9))\n",
    "dataset5 = dataset5.repeat(2).batch(5)\n",
    "for item in dataset5:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "dataset5 = dataset5.interleave(\n",
    "    lambda ele: tf.data.Dataset.from_tensor_slices(ele),\n",
    "    cycle_length=3,  # 3个并行取数据\n",
    "    block_length=3  # 一次取3个数据\n",
    ")\n",
    "\n",
    "for item in dataset5:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. map的用法\n",
    ">map 不改变dataset元素的数量， 只改变元素的数据结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 2. 3.], shape=(3,), dtype=float64)\n",
      "tf.Tensor([4. 5. 6.], shape=(3,), dtype=float64)\n",
      "tf.Tensor([7. 8. 9.], shape=(3,), dtype=float64)\n",
      "**********\n",
      "tf.Tensor([1. 2.], shape=(2,), dtype=float64)\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float64)\n",
      "==========\n",
      "tf.Tensor([4. 5.], shape=(2,), dtype=float64)\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float64)\n",
      "==========\n",
      "tf.Tensor([7. 8.], shape=(2,), dtype=float64)\n",
      "tf.Tensor(11, shape=(), dtype=int32)\n",
      "tf.Tensor(7.0, shape=(), dtype=float64)\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "dataset6 = tf.data.Dataset.from_tensor_slices(np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]))  \n",
    "\n",
    "for item in dataset6:\n",
    "    print(item)\n",
    "print(\"*\"*10)\n",
    "\n",
    "def func(ele):\n",
    "   # ele = ele +111\n",
    "    return ele[:2], 11, ele[0]\n",
    "\n",
    "dataset6 = dataset6.map(func)\n",
    "\n",
    "for x, y, z in dataset6:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(z)\n",
    "    print(\"=\"*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
