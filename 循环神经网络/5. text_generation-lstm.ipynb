{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.18.1\n",
      "pandas 0.25.3\n",
      "matplotlib 3.1.2\n",
      "sklearn 0.22.1\n",
      "tensorflow_core.python.keras.api._v2.keras 2.2.4-tf\n",
      "tensorflow 2.1.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "for module in [np, pd, mpl, sklearn, keras, tf]:\n",
    "    print(module.__name__, module.__version__)\n",
    "    \n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 词的处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - ### 2.1 词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "input_filepath = \"./shakespeare.txt\"\n",
    "\n",
    "with open(input_filepath, \"r\") as f:\n",
    "    text = f.read()\n",
    "    \n",
    "vocab = sorted(set(text))\n",
    "\n",
    "print(len(vocab))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - ### 2.2 id to char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n' ' ' '!' '$' '&' \"'\" ',' '-' '.' '3' ':' ';' '?' 'A' 'B' 'C' 'D' 'E'\n",
      " 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W'\n",
      " 'X' 'Y' 'Z' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o'\n",
      " 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n"
     ]
    }
   ],
   "source": [
    "id2char = np.array(vocab)\n",
    "print(id2char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - ### 2.3 char to id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n"
     ]
    }
   ],
   "source": [
    "char2id = {c:idx for idx, c in enumerate(vocab)}\n",
    "\n",
    "print(char2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - ### 2.4 text to id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59]\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "text_as_id = np.array([char2id[c] for c in text])\n",
    "\n",
    "print(text_as_id[:100])\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - ### 2.5 make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[35 13 30 ...  1 57 53]\n",
      " [59 58  1 ... 46 39 58]\n",
      " [10  0 14 ... 43 39 42]\n",
      " ...\n",
      " [ 1 58 53 ... 57 43  1]\n",
      " [60 43 42 ... 39 58  1]\n",
      " [39 50 50 ... 53 56  1]], shape=(64, 100), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[13 30 35 ... 57 53 59]\n",
      " [58  1 47 ... 39 58  1]\n",
      " [ 0 14 43 ... 39 42 44]\n",
      " ...\n",
      " [58 53 53 ... 43  1 56]\n",
      " [43 42 12 ... 58  1 58]\n",
      " [50 50  1 ... 56  1 58]], shape=(64, 100), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "batch_size = 64\n",
    "buffer_size = 10000\n",
    "\n",
    "def split_input_target(id_text):\n",
    "    return id_text[:-1], id_text[1:]\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_id)\n",
    "seq_dataset = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "seq_dataset = seq_dataset.map(split_input_target)\n",
    "seq_dataset = seq_dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "\n",
    "for item_x_batch, item_y_batch in seq_dataset.take(1):\n",
    "    print(item_x_batch)\n",
    "    print(item_y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 建模\n",
    "\n",
    "  - ### 3.1 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           16640     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 65)            66625     \n",
      "=================================================================\n",
      "Total params: 5,330,241\n",
      "Trainable params: 5,330,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
    "        keras.layers.LSTM(units=rnn_units,\n",
    "                              stateful = True,\n",
    "                              recurrent_initializer=\"glorot_uniform\",\n",
    "                              return_sequences=True),\n",
    "        keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - ### 3.2 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100)\n",
      "(64, 100)\n",
      "(64, 100, 65)\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in seq_dataset.take(1):\n",
    "    print(input_batch.shape)\n",
    "    print(target_batch.shape)\n",
    "    predictions_batch = model(input_batch)\n",
    "    print(predictions_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "# (100, 65) --> (100, 1)\n",
    "sample_slices = tf.random.categorical(logits=predictions_batch[0], num_samples=1)\n",
    "print(sample_slices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'virtuous deeds behind;\\nAnd would my father had left me no more!\\nFor all the rest is held at such a r'\n",
      "Output: 'irtuous deeds behind;\\nAnd would my father had left me no more!\\nFor all the rest is held at such a ra'\n",
      "Prediction: \"sOa- q-XWvysAQ?LM'E.-x-zmS3bFbKXbH&SG3apVEb\\nmskIH?IwhV.P:xe!W&jfcToMm$zsZIq-duQktWljn-?I,ixrfAD W;?m\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\", repr(\"\".join(id2char[input_batch[0]])))\n",
    "print(\"Output:\", repr(\"\".join(id2char[target_batch[0]])))\n",
    "print(\"Prediction:\", repr(\"\".join(id2char[tf.squeeze(sample_slices, axis=-1)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1, 65)\n"
     ]
    }
   ],
   "source": [
    "pred = model(tf.constant(np.zeros((batch_size, 1), dtype=np.int32)))\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - ### 3.3 失函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100)\n",
      "4.176166\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, predictions):\n",
    "    return keras.losses.sparse_categorical_crossentropy(labels, predictions, from_logits=True)\n",
    "\n",
    "test_loss = loss(target_batch, predictions_batch)\n",
    "print(test_loss.shape)\n",
    "print(test_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - ### 3.4 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 172 steps\n",
      "Epoch 1/100\n",
      "172/172 [==============================] - 11s 66ms/step - loss: 2.5684\n",
      "Epoch 2/100\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 1.8694\n",
      "Epoch 3/100\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 1.6270\n",
      "Epoch 4/100\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 1.4994\n",
      "Epoch 5/100\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 1.4205\n",
      "Epoch 6/100\n",
      "172/172 [==============================] - 10s 61ms/step - loss: 1.3654\n",
      "Epoch 7/100\n",
      "172/172 [==============================] - 10s 61ms/step - loss: 1.3214\n",
      "Epoch 8/100\n",
      "172/172 [==============================] - 10s 61ms/step - loss: 1.2826\n",
      "Epoch 9/100\n",
      "172/172 [==============================] - 10s 61ms/step - loss: 1.2475\n",
      "Epoch 10/100\n",
      "172/172 [==============================] - 10s 61ms/step - loss: 1.2137\n",
      "Epoch 11/100\n",
      "172/172 [==============================] - 10s 61ms/step - loss: 1.1790\n",
      "Epoch 12/100\n",
      "172/172 [==============================] - 11s 62ms/step - loss: 1.1439\n",
      "Epoch 13/100\n",
      "172/172 [==============================] - 11s 66ms/step - loss: 1.1066\n",
      "Epoch 14/100\n",
      "172/172 [==============================] - 12s 69ms/step - loss: 1.0693\n",
      "Epoch 15/100\n",
      "172/172 [==============================] - 14s 82ms/step - loss: 1.0296\n",
      "Epoch 16/100\n",
      "172/172 [==============================] - 13s 76ms/step - loss: 0.9902\n",
      "Epoch 17/100\n",
      "172/172 [==============================] - 15s 88ms/step - loss: 0.9496\n",
      "Epoch 18/100\n",
      "172/172 [==============================] - 15s 85ms/step - loss: 0.9099\n",
      "Epoch 19/100\n",
      "172/172 [==============================] - 16s 94ms/step - loss: 0.8699\n",
      "Epoch 20/100\n",
      "172/172 [==============================] - 16s 92ms/step - loss: 0.8322\n",
      "Epoch 21/100\n",
      "172/172 [==============================] - 17s 101ms/step - loss: 0.7955\n",
      "Epoch 22/100\n",
      "172/172 [==============================] - 18s 102ms/step - loss: 0.7621\n",
      "Epoch 23/100\n",
      "172/172 [==============================] - 17s 96ms/step - loss: 0.7308\n",
      "Epoch 24/100\n",
      "172/172 [==============================] - 18s 103ms/step - loss: 0.7004\n",
      "Epoch 25/100\n",
      "172/172 [==============================] - 18s 105ms/step - loss: 0.6744\n",
      "Epoch 26/100\n",
      "172/172 [==============================] - 16s 95ms/step - loss: 0.6502\n",
      "Epoch 27/100\n",
      "172/172 [==============================] - 19s 108ms/step - loss: 0.6271\n",
      "Epoch 28/100\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 0.6068\n",
      "Epoch 29/100\n",
      "172/172 [==============================] - 18s 104ms/step - loss: 0.5876\n",
      "Epoch 30/100\n",
      "172/172 [==============================] - 20s 116ms/step - loss: 0.5734\n",
      "Epoch 31/100\n",
      "172/172 [==============================] - 18s 103ms/step - loss: 0.5565\n",
      "Epoch 32/100\n",
      "172/172 [==============================] - 20s 114ms/step - loss: 0.5441\n",
      "Epoch 33/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.5326\n",
      "Epoch 34/100\n",
      "172/172 [==============================] - 18s 104ms/step - loss: 0.5193\n",
      "Epoch 35/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.5103\n",
      "Epoch 36/100\n",
      "172/172 [==============================] - 20s 114ms/step - loss: 0.5011\n",
      "Epoch 37/100\n",
      "172/172 [==============================] - 19s 108ms/step - loss: 0.4911\n",
      "Epoch 38/100\n",
      "172/172 [==============================] - 20s 119ms/step - loss: 0.4865\n",
      "Epoch 39/100\n",
      "172/172 [==============================] - 19s 111ms/step - loss: 0.4767\n",
      "Epoch 40/100\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 0.4704\n",
      "Epoch 41/100\n",
      "172/172 [==============================] - 20s 115ms/step - loss: 0.4651\n",
      "Epoch 42/100\n",
      "172/172 [==============================] - 20s 118ms/step - loss: 0.4591\n",
      "Epoch 43/100\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 0.4544\n",
      "Epoch 44/100\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 0.4518\n",
      "Epoch 45/100\n",
      "172/172 [==============================] - 20s 118ms/step - loss: 0.4471\n",
      "Epoch 46/100\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 0.4429\n",
      "Epoch 47/100\n",
      "172/172 [==============================] - 21s 122ms/step - loss: 0.4393\n",
      "Epoch 48/100\n",
      "172/172 [==============================] - 19s 112ms/step - loss: 0.4384\n",
      "Epoch 49/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.4322\n",
      "Epoch 50/100\n",
      "172/172 [==============================] - 21s 123ms/step - loss: 0.4309\n",
      "Epoch 51/100\n",
      "172/172 [==============================] - 19s 108ms/step - loss: 0.4289\n",
      "Epoch 52/100\n",
      "172/172 [==============================] - 20s 114ms/step - loss: 0.4278\n",
      "Epoch 53/100\n",
      "172/172 [==============================] - 19s 108ms/step - loss: 0.4219\n",
      "Epoch 54/100\n",
      "172/172 [==============================] - 19s 113ms/step - loss: 0.4203\n",
      "Epoch 55/100\n",
      "172/172 [==============================] - 19s 113ms/step - loss: 0.4191\n",
      "Epoch 56/100\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 0.4174\n",
      "Epoch 57/100\n",
      "172/172 [==============================] - 21s 120ms/step - loss: 0.4157\n",
      "Epoch 58/100\n",
      "172/172 [==============================] - 18s 104ms/step - loss: 0.4131\n",
      "Epoch 59/100\n",
      "172/172 [==============================] - 20s 115ms/step - loss: 0.4125\n",
      "Epoch 60/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.4131\n",
      "Epoch 61/100\n",
      "172/172 [==============================] - 20s 114ms/step - loss: 0.4101\n",
      "Epoch 62/100\n",
      "172/172 [==============================] - 20s 118ms/step - loss: 0.4087\n",
      "Epoch 63/100\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 0.4089\n",
      "Epoch 64/100\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 0.4076\n",
      "Epoch 65/100\n",
      "172/172 [==============================] - 20s 119ms/step - loss: 0.4057\n",
      "Epoch 66/100\n",
      "172/172 [==============================] - 19s 111ms/step - loss: 0.4025\n",
      "Epoch 67/100\n",
      "172/172 [==============================] - 19s 112ms/step - loss: 0.4034\n",
      "Epoch 68/100\n",
      "172/172 [==============================] - 20s 116ms/step - loss: 0.4055\n",
      "Epoch 69/100\n",
      "172/172 [==============================] - 20s 116ms/step - loss: 0.4031\n",
      "Epoch 70/100\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 0.4013\n",
      "Epoch 71/100\n",
      "172/172 [==============================] - 21s 120ms/step - loss: 0.3986\n",
      "Epoch 72/100\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 0.3979\n",
      "Epoch 73/100\n",
      "172/172 [==============================] - 20s 115ms/step - loss: 0.3993\n",
      "Epoch 74/100\n",
      "172/172 [==============================] - 20s 116ms/step - loss: 0.4000\n",
      "Epoch 75/100\n",
      "172/172 [==============================] - 19s 111ms/step - loss: 0.3997\n",
      "Epoch 76/100\n",
      "172/172 [==============================] - 19s 112ms/step - loss: 0.3966\n",
      "Epoch 77/100\n",
      "172/172 [==============================] - 20s 119ms/step - loss: 0.3964\n",
      "Epoch 78/100\n",
      "172/172 [==============================] - 19s 113ms/step - loss: 0.3961\n",
      "Epoch 79/100\n",
      "172/172 [==============================] - 18s 106ms/step - loss: 0.3955\n",
      "Epoch 80/100\n",
      "172/172 [==============================] - 20s 118ms/step - loss: 0.3960\n",
      "Epoch 81/100\n",
      "172/172 [==============================] - 20s 113ms/step - loss: 0.3957\n",
      "Epoch 82/100\n",
      "172/172 [==============================] - 20s 116ms/step - loss: 0.3964\n",
      "Epoch 83/100\n",
      "172/172 [==============================] - 18s 106ms/step - loss: 0.3953\n",
      "Epoch 84/100\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 0.3944\n",
      "Epoch 85/100\n",
      "172/172 [==============================] - 20s 114ms/step - loss: 0.3934\n",
      "Epoch 86/100\n",
      "172/172 [==============================] - 19s 108ms/step - loss: 0.3933\n",
      "Epoch 87/100\n",
      "172/172 [==============================] - 19s 111ms/step - loss: 0.3916\n",
      "Epoch 88/100\n",
      "172/172 [==============================] - 20s 117ms/step - loss: 0.3905\n",
      "Epoch 89/100\n",
      "172/172 [==============================] - 18s 105ms/step - loss: 0.3910\n",
      "Epoch 90/100\n",
      "172/172 [==============================] - 19s 113ms/step - loss: 0.3916\n",
      "Epoch 91/100\n",
      "172/172 [==============================] - 19s 111ms/step - loss: 0.3918\n",
      "Epoch 92/100\n",
      "172/172 [==============================] - 19s 112ms/step - loss: 0.3936\n",
      "Epoch 93/100\n",
      "172/172 [==============================] - 19s 111ms/step - loss: 0.3894\n",
      "Epoch 94/100\n",
      "172/172 [==============================] - 19s 111ms/step - loss: 0.3907\n",
      "Epoch 95/100\n",
      "172/172 [==============================] - 21s 119ms/step - loss: 0.3873\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 21s 120ms/step - loss: 0.3883\n",
      "Epoch 97/100\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 0.3916\n",
      "Epoch 98/100\n",
      "172/172 [==============================] - 20s 118ms/step - loss: 0.3924\n",
      "Epoch 99/100\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 0.3916\n",
      "Epoch 100/100\n",
      "172/172 [==============================] - 21s 125ms/step - loss: 0.3900\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=loss, optimizer=keras.optimizers.Adam())\n",
    "\n",
    "output_dir = \"text_generation_checkpoints\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "    \n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\n",
    "                    filepath=os.path.join(output_dir, \"ckpt_{epoch}\"),\n",
    "                    monitor=\"loss\",\n",
    "                    save_weights_only=True)]\n",
    "\n",
    "history = model.fit(seq_dataset, epochs=100, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 生成文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_generation_checkpoints/ckpt_100\n"
     ]
    }
   ],
   "source": [
    "model_path = tf.train.latest_checkpoint(output_dir)\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            16640     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (1, None, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 65)             66625     \n",
      "=================================================================\n",
      "Total params: 5,330,241\n",
      "Trainable params: 5,330,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model2.load_weights(model_path)\n",
    "model2.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: the pretty point,\n",
      "Your company is fall down in my territories:\n",
      "And we can curse the grief on't.\n",
      "\n",
      "ALONSO:\n",
      "Prithee, peace.\n",
      "\n",
      "SEBASTIAN:\n",
      "You were kneel'd to and in a seeming; part;\n",
      "Let me desire your sister's revenge, my father's brother's son,\n",
      "Now, by my sceptre's awn, being the time may call thee straight.\n",
      "\n",
      "RICHARD:\n",
      "Fear me of the duke.\n",
      "\n",
      "SEBASTIAN:\n",
      "Nay, pardon or prosperiously.\n",
      "\n",
      "First Gentleman:\n",
      "Why, no; for he hath made a soldier: do they say,\n",
      "That seem so fair a tremble. Adieu,\n",
      "Your friends for ever may they chance to seek to have thee dead.\n",
      "\n",
      "GLOUCESTER:\n",
      "Come, let us to the people.\n",
      "\n",
      "CORIOLANUS:\n",
      "I'll give my cousin.\n",
      "\n",
      "JULIET:\n",
      "Then have you done thy dutyous enemy?\n",
      "Further I shall see thee, there art thou not mad\n",
      "Hay thus to have a mouth in our arms.\n",
      "I, field, thou true meaning in my cousin's death!\n",
      "\n",
      "LADY CAPULET:\n",
      "Well, this is a pity; it is not in the blood\n",
      "First Senator: there to my soul to thee;\n",
      "And here have they say, being richer than innocency, stands for the facing.\n",
      "\n",
      "ELBOW:\n",
      "Come you\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_string, temperature = 1,num_generate = 1000):\n",
    "    input_eval = [char2id[c] for c in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, axis=0)\n",
    "    \n",
    "    text_generated = []\n",
    "    model.reset_states()\n",
    "    \n",
    "    for _ in range(num_generate):\n",
    "        \n",
    "        # 预测\n",
    "        prediction = model(input_eval)\n",
    "        prediction = tf.squeeze(prediction, axis=0)\n",
    "        prediction = prediction / temperature\n",
    "        \n",
    "        # 获取最后一个预测值\n",
    "        prediction_id = tf.random.categorical(logits=prediction, num_samples=1)[-1, 0].numpy()\n",
    "        \n",
    "        # 对应预测文本\n",
    "        text_generated.append(id2char[prediction_id])\n",
    "        \n",
    "        # 下一次预测的预测值\n",
    "        input_eval = tf.expand_dims([prediction_id], axis=0)\n",
    "        \n",
    "    return start_string + \"\".join(text_generated)\n",
    "        \n",
    "new_text = generate_text(model2, \"All: \", temperature=0.5)\n",
    "print(new_text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
